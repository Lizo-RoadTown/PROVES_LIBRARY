{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVES Library - Setup and Exploration\n",
    "\n",
    "This notebook will help you:\n",
    "1. Test the Neon PostgreSQL connection\n",
    "2. Apply the database schema (knowledge graph tables)\n",
    "3. Index your first library entry\n",
    "4. Explore the knowledge graph\n",
    "5. Prototype the Curator agent\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Neon MCP server connected (23 tools available)\n",
    "- `.env` file with `NEON_DATABASE_URL` filled in\n",
    "- Python virtual environment activated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add scripts directory to path\n",
    "project_root = Path.cwd().parent\n",
    "scripts_dir = project_root / 'scripts'\n",
    "sys.path.insert(0, str(scripts_dir))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "print(f\"‚úÖ Project root: {project_root}\")\n",
    "print(f\"‚úÖ Scripts directory added to path\")\n",
    "print(f\"‚úÖ Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our utilities\n",
    "from db_connector import get_db\n",
    "from graph_manager import GraphManager\n",
    "from library_indexer import LibraryIndexer\n",
    "\n",
    "# For visualization\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ All utilities imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection to Neon\n",
    "db = get_db()\n",
    "\n",
    "# Get PostgreSQL version\n",
    "result = db.fetch_one(\"SELECT version() as version\")\n",
    "print(f\"‚úÖ Connected to PostgreSQL\")\n",
    "print(f\"\\nVersion: {result['version'][:80]}...\")\n",
    "\n",
    "# Get database name\n",
    "db_info = db.fetch_one(\"SELECT current_database() as db_name, current_user as user_name\")\n",
    "print(f\"\\nDatabase: {db_info['db_name']}\")\n",
    "print(f\"User: {db_info['user_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Database Schema\n",
    "\n",
    "This will create all the tables for:\n",
    "- Knowledge graph (nodes and relationships)\n",
    "- Library entries\n",
    "- Risk patterns and scans\n",
    "- Agent workflows (Curator and Builder)\n",
    "\n",
    "**Note:** This will only run if the tables don't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if schema already exists\n",
    "check_query = \"\"\"\n",
    "SELECT EXISTS (\n",
    "    SELECT FROM information_schema.tables \n",
    "    WHERE table_name = 'library_entries'\n",
    ") as schema_exists\n",
    "\"\"\"\n",
    "\n",
    "result = db.fetch_one(check_query)\n",
    "\n",
    "if result['schema_exists']:\n",
    "    print(\"‚ö†Ô∏è  Schema already exists. Skipping schema creation.\")\n",
    "    print(\"If you need to reset, manually drop tables in Neon console.\")\n",
    "else:\n",
    "    print(\"üìù Schema not found. Applying schema files...\")\n",
    "    print(\"\\nThis may take 30-60 seconds...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply schema if needed\n",
    "if not result['schema_exists']:\n",
    "    schema_dir = project_root / 'mcp-server' / 'schema'\n",
    "    \n",
    "    # Read and execute 00_initial_schema.sql\n",
    "    print(\"üìÑ Applying 00_initial_schema.sql...\")\n",
    "    with open(schema_dir / '00_initial_schema.sql', 'r') as f:\n",
    "        schema_sql = f.read()\n",
    "    \n",
    "    db.execute(schema_sql)\n",
    "    print(\"‚úÖ Initial schema applied\")\n",
    "    \n",
    "    # Read and execute 01_seed_data.sql\n",
    "    print(\"\\nüìÑ Applying 01_seed_data.sql...\")\n",
    "    with open(schema_dir / '01_seed_data.sql', 'r') as f:\n",
    "        seed_sql = f.read()\n",
    "    \n",
    "    db.execute(seed_sql)\n",
    "    print(\"‚úÖ Seed data applied\")\n",
    "    \n",
    "    print(\"\\nüéâ Database schema initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Schema Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get database statistics\n",
    "stats = db.fetch_all(\"SELECT * FROM database_statistics ORDER BY table_name\")\n",
    "stats_df = pd.DataFrame(stats)\n",
    "\n",
    "print(\"üìä Database Statistics:\\n\")\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "total_rows = stats_df['row_count'].sum()\n",
    "print(f\"\\nTotal rows across all tables: {total_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore Initial Seed Data\n",
    "\n",
    "The seed data includes:\n",
    "- 5 risk patterns (I2C conflict, memory leak, power budget, etc.)\n",
    "- Example hardware nodes (MPU-6050 IMU, BNO055 IMU, TCA9548A multiplexer)\n",
    "- Example F¬¥ components\n",
    "- Example relationships showing conflicts and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View risk patterns\n",
    "risk_patterns = db.fetch_all(\"\"\"\n",
    "    SELECT name, pattern_type, severity, detection_method, fix_summary\n",
    "    FROM risk_patterns\n",
    "    ORDER BY \n",
    "        CASE severity\n",
    "            WHEN 'critical' THEN 1\n",
    "            WHEN 'high' THEN 2\n",
    "            WHEN 'medium' THEN 3\n",
    "            WHEN 'low' THEN 4\n",
    "        END\n",
    "\"\"\")\n",
    "\n",
    "print(\"üîç Risk Patterns:\\n\")\n",
    "risk_df = pd.DataFrame(risk_patterns)\n",
    "print(risk_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View knowledge graph nodes\n",
    "gm = GraphManager()\n",
    "stats = gm.get_statistics()\n",
    "\n",
    "print(\"üåê Knowledge Graph Statistics:\\n\")\n",
    "print(f\"Total Nodes: {stats['total_nodes']}\")\n",
    "print(f\"Total Relationships: {stats['total_relationships']}\")\n",
    "\n",
    "if stats['nodes_by_type']:\n",
    "    print(\"\\nNodes by Type:\")\n",
    "    for node_type, count in stats['nodes_by_type'].items():\n",
    "        print(f\"  {node_type}: {count}\")\n",
    "\n",
    "if stats['relationships_by_type']:\n",
    "    print(\"\\nRelationships by Type:\")\n",
    "    for rel_type, count in stats['relationships_by_type'].items():\n",
    "        print(f\"  {rel_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View hardware nodes in detail\n",
    "hardware = gm.search_nodes(node_type='hardware')\n",
    "\n",
    "print(\"üîß Hardware Components:\\n\")\n",
    "for node in hardware:\n",
    "    print(f\"\\n{node['name']}\")\n",
    "    print(f\"  Description: {node['description']}\")\n",
    "    print(f\"  Properties:\")\n",
    "    props = node['properties']\n",
    "    for key, value in props.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explore Relationships (ERV)\n",
    "\n",
    "The Engineering Relationship Vocabulary (ERV) defines 6 relationship types:\n",
    "- `depends_on` - Component A depends on Component B\n",
    "- `conflicts_with` - Component A conflicts with Component B\n",
    "- `enables` - Component A enables capability B\n",
    "- `requires` - Component A requires condition/config B\n",
    "- `mitigates` - Solution A mitigates risk B\n",
    "- `causes` - Action A causes consequence B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all relationships\n",
    "relationships = db.fetch_all(\"\"\"\n",
    "    SELECT \n",
    "        sn.name as source,\n",
    "        r.relationship_type,\n",
    "        tn.name as target,\n",
    "        r.description,\n",
    "        r.is_critical\n",
    "    FROM kg_relationships r\n",
    "    JOIN kg_nodes sn ON r.source_node_id = sn.id\n",
    "    JOIN kg_nodes tn ON r.target_node_id = tn.id\n",
    "    ORDER BY r.is_critical DESC, r.relationship_type\n",
    "\"\"\")\n",
    "\n",
    "print(\"üîó Knowledge Graph Relationships:\\n\")\n",
    "for rel in relationships:\n",
    "    critical = \"‚ö†Ô∏è \" if rel['is_critical'] else \"\"\n",
    "    print(f\"{critical}{rel['source']} --[{rel['relationship_type']}]--> {rel['target']}\")\n",
    "    print(f\"  {rel['description']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Index Library Entry\n",
    "\n",
    "Now let's index the existing I2C conflict example from the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize indexer\n",
    "indexer = LibraryIndexer()\n",
    "\n",
    "print(\"üìö Indexing library entries...\\n\")\n",
    "stats = indexer.index_all(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View indexed entries\n",
    "entries = db.fetch_all(\"\"\"\n",
    "    SELECT \n",
    "        title,\n",
    "        entry_type,\n",
    "        domain,\n",
    "        array_length(tags, 1) as tag_count,\n",
    "        array_length(sources, 1) as source_count,\n",
    "        quality_tier,\n",
    "        created_at\n",
    "    FROM library_entries\n",
    "    ORDER BY created_at DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìñ Library Entries:\\n\")\n",
    "entries_df = pd.DataFrame(entries)\n",
    "print(entries_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View entry details\n",
    "entry = db.fetch_one(\"\"\"\n",
    "    SELECT *\n",
    "    FROM library_entries\n",
    "    WHERE slug = 'example-i2c-conflict'\n",
    "\"\"\")\n",
    "\n",
    "if entry:\n",
    "    print(\"üìÑ Entry Details:\\n\")\n",
    "    print(f\"Title: {entry['title']}\")\n",
    "    print(f\"Type: {entry['entry_type']}\")\n",
    "    print(f\"Domain: {entry['domain']}\")\n",
    "    print(f\"Tags: {', '.join(entry['tags'])}\")\n",
    "    print(f\"Sources: {len(entry['sources'])} citations\")\n",
    "    print(f\"\\nSummary:\\n{entry['summary'][:300]}...\")\n",
    "else:\n",
    "    print(\"Entry not found. Check if the file exists in library/software/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Graph Queries\n",
    "\n",
    "Let's test some common graph queries that the agents will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for conflict relationships\n",
    "conflicts = db.fetch_all(\"\"\"\n",
    "    SELECT \n",
    "        sn.name as source,\n",
    "        tn.name as target,\n",
    "        r.description,\n",
    "        r.strength\n",
    "    FROM kg_relationships r\n",
    "    JOIN kg_nodes sn ON r.source_node_id = sn.id\n",
    "    JOIN kg_nodes tn ON r.target_node_id = tn.id\n",
    "    WHERE r.relationship_type = 'conflicts_with'\n",
    "    ORDER BY r.strength DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚ö†Ô∏è  Component Conflicts:\\n\")\n",
    "for conflict in conflicts:\n",
    "    print(f\"{conflict['source']} <--> {conflict['target']}\")\n",
    "    print(f\"  Strength: {conflict['strength']}\")\n",
    "    print(f\"  {conflict['description']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the I2C multiplexer node\n",
    "multiplexer = gm.get_node_by_name('TCA9548A I2C Multiplexer', 'hardware')\n",
    "\n",
    "if multiplexer:\n",
    "    print(\"üîå TCA9548A I2C Multiplexer:\\n\")\n",
    "    print(f\"ID: {multiplexer['id']}\")\n",
    "    print(f\"Description: {multiplexer['description']}\")\n",
    "    \n",
    "    # Get its relationships\n",
    "    rels = gm.get_node_relationships(multiplexer['id'])\n",
    "    \n",
    "    print(f\"\\nRelationships ({len(rels)}):\")\n",
    "    for rel in rels:\n",
    "        print(f\"  {rel['relationship_type']}: {rel['target_name']}\")\n",
    "        print(f\"    {rel['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prototype: Curator Agent\n",
    "\n",
    "Let's prototype the Curator agent's workflow:\n",
    "1. Take a raw capture (unstructured text)\n",
    "2. Extract citations and metadata\n",
    "3. Check for duplicates in the graph\n",
    "4. Generate a normalized library entry\n",
    "5. Score quality\n",
    "\n",
    "We'll use a simulated capture for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated raw capture from a GitHub issue\n",
    "raw_capture = \"\"\"\n",
    "We ran into a major problem during integration testing last week. \n",
    "Two IMU sensors (MPU-6050 and BNO055) both defaulted to I2C address 0x68. \n",
    "The system would hang during initialization because of the address collision.\n",
    "\n",
    "After some research, we found that using a TCA9548A I2C multiplexer solved the issue.\n",
    "We put each IMU on a separate channel of the multiplexer. \n",
    "\n",
    "Testing showed no performance impact. The solution has been stable for 3 weeks now.\n",
    "\n",
    "References:\n",
    "- https://github.com/example/cubesat/issues/456\n",
    "- https://www.ti.com/product/TCA9548A\n",
    "- Commit: abc123def\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Raw Capture:\\n\")\n",
    "print(raw_capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a curator job (for tracking)\n",
    "job_query = \"\"\"\n",
    "    INSERT INTO curator_jobs (raw_capture_text, source_url, status, stage)\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "    RETURNING id\n",
    "\"\"\"\n",
    "\n",
    "job = db.fetch_one(\n",
    "    job_query,\n",
    "    (raw_capture, 'https://github.com/example/cubesat/issues/456', 'processing', 'citation_extraction')\n",
    ")\n",
    "\n",
    "job_id = job['id']\n",
    "print(f\"‚úÖ Created curator job: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract Citations (Simulated)\n",
    "\n",
    "In the full agent, this would use an LLM to extract citations, hardware mentions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated extraction (in real agent, this would use Claude/GPT)\n",
    "extracted_metadata = {\n",
    "    'title': 'I2C Address Conflict Between MPU-6050 and BNO055',\n",
    "    'problem': 'Address collision on I2C bus causing system hang',\n",
    "    'solution': 'Use TCA9548A I2C multiplexer to separate devices',\n",
    "    'hardware_mentioned': ['MPU-6050', 'BNO055', 'TCA9548A'],\n",
    "    'citations': [\n",
    "        'https://github.com/example/cubesat/issues/456',\n",
    "        'https://www.ti.com/product/TCA9548A'\n",
    "    ],\n",
    "    'verification': 'Tested stable for 3 weeks',\n",
    "    'domain': 'software',\n",
    "    'type': 'failure',\n",
    "    'tags': ['i2c', 'hardware', 'multiplexer', 'integration']\n",
    "}\n",
    "\n",
    "print(\"üîç Extracted Metadata:\\n\")\n",
    "print(json.dumps(extracted_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for similar entries\n",
    "similar = db.fetch_all(\"\"\"\n",
    "    SELECT title, slug, entry_type, domain\n",
    "    FROM library_entries\n",
    "    WHERE tags && %s  -- Array overlap operator\n",
    "    ORDER BY array_length(tags, 1) DESC\n",
    "    LIMIT 5\n",
    "\"\"\", (extracted_metadata['tags'],))\n",
    "\n",
    "print(\"üîç Similar Entries:\\n\")\n",
    "if similar:\n",
    "    for entry in similar:\n",
    "        print(f\"  - {entry['title']} ({entry['slug']})\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  Possible duplicate detected. Would flag for human review.\")\n",
    "else:\n",
    "    print(\"  No similar entries found. This appears to be a new pattern.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Quality Scoring (Simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated quality scoring\n",
    "def score_quality(metadata, raw_text):\n",
    "    \"\"\"\n",
    "    Score quality based on:\n",
    "    - Citation count (0-1 scale)\n",
    "    - Verification present (0-1)\n",
    "    - Completeness (problem + solution + verification)\n",
    "    - Hardware specificity\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # Citation score (>= 2 citations = 1.0)\n",
    "    citation_count = len(metadata.get('citations', []))\n",
    "    scores['citations'] = min(citation_count / 2.0, 1.0)\n",
    "    \n",
    "    # Verification score\n",
    "    scores['verification'] = 1.0 if metadata.get('verification') else 0.0\n",
    "    \n",
    "    # Completeness (has problem, solution, verification)\n",
    "    has_problem = bool(metadata.get('problem'))\n",
    "    has_solution = bool(metadata.get('solution'))\n",
    "    has_verification = bool(metadata.get('verification'))\n",
    "    scores['completeness'] = (has_problem + has_solution + has_verification) / 3.0\n",
    "    \n",
    "    # Hardware specificity (>= 2 components mentioned)\n",
    "    hw_count = len(metadata.get('hardware_mentioned', []))\n",
    "    scores['hardware_specificity'] = min(hw_count / 2.0, 1.0)\n",
    "    \n",
    "    # Overall score (weighted average)\n",
    "    overall = (\n",
    "        scores['citations'] * 0.25 +\n",
    "        scores['verification'] * 0.30 +\n",
    "        scores['completeness'] * 0.30 +\n",
    "        scores['hardware_specificity'] * 0.15\n",
    "    )\n",
    "    \n",
    "    return overall, scores\n",
    "\n",
    "quality_score, component_scores = score_quality(extracted_metadata, raw_capture)\n",
    "\n",
    "print(\"üìä Quality Scoring:\\n\")\n",
    "print(f\"Component Scores:\")\n",
    "for component, score in component_scores.items():\n",
    "    print(f\"  {component}: {score:.2f}\")\n",
    "\n",
    "print(f\"\\nOverall Score: {quality_score:.2f}\")\n",
    "\n",
    "if quality_score >= 0.8:\n",
    "    tier = 'high'\n",
    "elif quality_score >= 0.5:\n",
    "    tier = 'medium'\n",
    "else:\n",
    "    tier = 'low'\n",
    "\n",
    "print(f\"Quality Tier: {tier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Update Curator Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update job with quality assessment\n",
    "update_query = \"\"\"\n",
    "    UPDATE curator_jobs\n",
    "    SET \n",
    "        status = %s,\n",
    "        stage = %s,\n",
    "        quality_issues = %s,\n",
    "        needs_human_review = %s\n",
    "    WHERE id = %s\n",
    "\"\"\"\n",
    "\n",
    "quality_issues = {\n",
    "    'overall_score': quality_score,\n",
    "    'tier': tier,\n",
    "    'possible_duplicate': len(similar) > 0,\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "if quality_score < 0.8:\n",
    "    quality_issues['recommendations'].append('Consider adding more citations')\n",
    "\n",
    "db.execute(\n",
    "    update_query,\n",
    "    ('completed', 'quality_scoring', json.dumps(quality_issues), len(similar) > 0, str(job_id))\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Curator job updated\")\n",
    "print(f\"\\nRecommendations:\")\n",
    "for rec in quality_issues['recommendations']:\n",
    "    print(f\"  - {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished ‚úÖ\n",
    "\n",
    "1. Connected to Neon PostgreSQL database\n",
    "2. Applied knowledge graph schema (9 tables)\n",
    "3. Loaded seed data (5 risk patterns, example nodes)\n",
    "4. Indexed library entry from markdown\n",
    "5. Explored knowledge graph relationships\n",
    "6. Prototyped Curator agent workflow\n",
    "\n",
    "### Next Steps üöÄ\n",
    "\n",
    "1. **Build Full Curator Agent** (LangGraph workflow)\n",
    "   - Use Claude API for citation extraction\n",
    "   - Implement duplicate detection with embeddings\n",
    "   - Add human review workflow\n",
    "\n",
    "2. **Build Builder Agent** (F¬¥ code generation)\n",
    "   - Pattern search in knowledge graph\n",
    "   - Template-based code generation\n",
    "   - Test generation and validation\n",
    "\n",
    "3. **Implement Risk Scanner**\n",
    "   - AST parsing for Python/C++\n",
    "   - Graph-enhanced cascade detection\n",
    "   - GitHub integration for PRs\n",
    "\n",
    "4. **Add Vector Embeddings**\n",
    "   - Generate embeddings for library entries\n",
    "   - Semantic search implementation\n",
    "   - Similarity-based duplicate detection\n",
    "\n",
    "5. **Build MCP Server**\n",
    "   - FastAPI endpoints\n",
    "   - Expose graph queries via MCP\n",
    "   - Integration with Claude Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final statistics\n",
    "final_stats = db.fetch_all(\"SELECT * FROM database_statistics ORDER BY table_name\")\n",
    "\n",
    "print(\"üìä Final Database Statistics:\\n\")\n",
    "stats_df = pd.DataFrame(final_stats)\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete! Ready to build the full agentic system.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
