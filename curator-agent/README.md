# PROVES Library Curator Agent

**LangGraph-based agent for extracting CubeSat dependencies from documentation**

## Overview

The Curator Agent analyzes technical documentation (FÂ´ framework, PROVES Kit) and extracts dependency relationships into a knowledge graph. It captures ALL data to staging tables, then humans verify EVERY piece before it enters the truth graph.

## Quick Start

```bash
# 1. Ensure .env is configured (see ../GETTING_STARTED.md)

# 2. Run with human verification for staged items
python run_with_approval.py

# 3. Or run the test script
python test_agent.py
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CURATOR AGENT (Claude Sonnet 4.5)                          â”‚
â”‚  - Coordinates sub-agents                                   â”‚
â”‚  - Prepares data for HUMAN verification                     â”‚
â”‚  - Provides context to eliminate ambiguity                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXTRACTOR â”‚  â”‚VALIDATOR â”‚  â”‚   STORAGE    â”‚
â”‚(Sonnet 4.5)  â”‚(Haiku 3.5)  â”‚ (Haiku 3.5)  â”‚
â”‚             â”‚             â”‚               â”‚
â”‚ Captures   â”‚  â”‚ Flags    â”‚  â”‚ Routes to   â”‚
â”‚ ALL data   â”‚  â”‚ anomaliesâ”‚  â”‚ staging     â”‚
â”‚ + context  â”‚  â”‚ + notes  â”‚  â”‚ tables      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ HUMAN VERIFICATION â”‚
              â”‚ (Reviews EACH piece)â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   TRUTH GRAPH      â”‚
              â”‚  (Neon PostgreSQL) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cost Optimization:** Haiku for simple tasks = 90% savings on sub-agents!

## File Structure

```
curator-agent/
â”œâ”€â”€ src/curator/
â”‚   â”œâ”€â”€ agent.py              # Main curator agent + HITL
â”‚   â””â”€â”€ subagents/
â”‚       â”œâ”€â”€ extractor.py      # Document analysis
â”‚       â”œâ”€â”€ validator.py      # Duplicate checking
â”‚       â””â”€â”€ storage.py        # Database storage
â”œâ”€â”€ run_with_approval.py      # CLI entry point
â”œâ”€â”€ test_agent.py             # Basic test
â”œâ”€â”€ test_autonomous_exploration.py
â”œâ”€â”€ test_full_extraction.py
â”œâ”€â”€ test_simple_extraction.py
â”œâ”€â”€ langgraph.json            # LangGraph deployment config
â””â”€â”€ pyproject.toml            # Python package definition
```

## How It Works

1. **Input:** Path to documentation file (markdown, code, specs)
2. **Extractor:** Captures ALL raw data with smart categorization and lineage
3. **Validator:** Checks confidence, flags anomalies, notes pattern breaks
4. **Storage:** Routes to staging tables (clean or flagged with reasoning)
5. **Human Verification:** Human reviews EACH piece, aligns across sources
6. **Truth Graph:** Only human-verified data enters the knowledge graph

### ERV Relationship Types

| Type | Meaning | Example |
|------|---------|---------|
| `depends_on` | Runtime dependency | ImuManager â†’ LinuxI2cDriver |
| `requires` | Build requirement | Component â†’ Toolchain |
| `enables` | Makes possible | LoadSwitch â†’ SensorPower |
| `conflicts_with` | Incompatible | UARTDebug â†” RadioTX |
| `mitigates` | Reduces risk | Watchdog â†’ InfiniteLoop |
| `causes` | Leads to | BrownoutReset â†’ StateCorruption |

### Criticality Levels (Post-Verification Metadata)

| Level | Meaning | Assigned By |
|-------|---------|-------------|
| **HIGH** | Mission-critical | Human during verification |
| **MEDIUM** | Important | Human during verification |
| **LOW** | Minor impact | Human during verification |

> **Note:** Criticality is metadata assigned by humans AFTER verification.

## Configuration

The agent uses environment variables from `../.env`:

```bash
# Required
ANTHROPIC_API_KEY=sk-ant-api03-...
DATABASE_URL=postgresql://...

# Optional (tracing disabled by default)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=lsv2_pt_...
```

## State Persistence

Agent state is persisted using LangGraph's PostgresSaver checkpointer:
- Checkpoints stored in Neon PostgreSQL
- Tables: `checkpoints`, `checkpoint_blobs`, `checkpoint_writes`, `checkpoint_migrations`
- Created by: `python ../scripts/setup_checkpointer.py`

## Current Status

ðŸ”„ **In Development**

The agent is functional but workflow refinement is ongoing:
- [ ] Stop conditions need tuning (agent loops on extractor calls)
- [ ] Task/outcome definition needs clarity
- [ ] Integration testing with trial documents

## Training Data

HITL interactions can be exported for fine-tuning local LLMs.
See: `../notebooks/02_training_local_llm.ipynb`

---

Last Updated: December 22, 2025
